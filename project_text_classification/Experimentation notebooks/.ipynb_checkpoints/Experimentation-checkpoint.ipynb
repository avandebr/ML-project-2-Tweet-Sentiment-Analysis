{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "import re\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write(list_,name):\n",
    "    f = open(name,'w')\n",
    "    for s in list_:\n",
    "        f.write(str(s) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for all datasets except for SST.\n",
    "    Original taken from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string) \n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    return string.strip().lower()\n",
    "\n",
    "\n",
    "def load_data_and_labels(positive_data_file, negative_data_file):\n",
    "    \"\"\"\n",
    "    Loads the training data, splits the data into words and generates labels.\n",
    "    Returns split sentences and labels.\n",
    "\n",
    "    IN : \n",
    "    positive_data_file :    path to the positive data file\n",
    "    negative_data_file :    path to the negative data file\n",
    "    \"\"\"\n",
    "    # Load data from files\n",
    "    positive_examples = list(open(positive_data_file, \"r\").readlines())\n",
    "    positive_examples = [s.strip() for s in positive_examples]\n",
    "\n",
    "    negative_examples = list(open(negative_data_file, \"r\").readlines())\n",
    "    negative_examples = [s.strip() for s in negative_examples]\n",
    "\n",
    "    # Split by words\n",
    "    x_text = positive_examples + negative_examples\n",
    "    x_text = [clean_str(sent) for sent in x_text]\n",
    "\n",
    "    # Generate labels\n",
    "    positive_labels = [[0, 1] for _ in positive_examples]\n",
    "    negative_labels = [[1, 0] for _ in negative_examples]\n",
    "    y = np.concatenate([positive_labels, negative_labels], 0)\n",
    "    return [x_text, y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positive_data_file = \"../twitter-datasets/train_pos.txt\"\n",
    "negative_data_file = \"../twitter-datasets/train_neg.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_raw, y_test = load_data_and_labels(positive_data_file,negative_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user i dunno justin read my mention or not only justin and god knows about that , but i hope you will follow me believe 15', \"because your logic is so dumb , i wo n't even crop out your name or your photo tsk url\", 'user just put casper in a box ! looved the battle ! crakkbitch', \"user user thanks sir do n't trip lil mama just keep doin ya thang !\", 'visiting my brother tmr is the bestest birthday gift eveerrr ! ! !', 'user yay ! ! lifecompleted tweet facebook me to let me know please', 'user 1dnextalbumtitle feel for you rollercoaster of life song cocept life , yolo , becoming famous \\\\? 3 14 followmeplz ! 3 x15', \"workin hard or hardly workin rt user at hardee 's with my future coworker user\", \"user i saw i 'll be replying in a bit\", 'this is were i belong']\n"
     ]
    }
   ],
   "source": [
    "print(x_raw[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def delete_duplicate_lines(x_raw,y):\n",
    "    \"\"\"\n",
    "    To delete the lines that are identical in the training data\n",
    "    \n",
    "    IN : \n",
    "    x_raw :  clean data (list of clean sentences)\n",
    "    y : associated labels\n",
    "    \"\"\"\n",
    "    print(\"Deleting duplicates in data...\")\n",
    "    seen = set()\n",
    "    unique_x = []\n",
    "    unique_y = []\n",
    "    for i,line in enumerate(x_raw):\n",
    "        if line not in seen:\n",
    "            seen.add(line)\n",
    "            unique_x.append(line)\n",
    "            unique_y.append(y[i])\n",
    "    perc_duplicate = (len(x_raw)-len(unique_x))/(len(x_raw))*100\n",
    "    print(\"Found : {}% duplicates in the input\".format(perc_duplicate,len(x_raw)))\n",
    "    return unique_x,unique_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found : 9.39% duplicates in the input\n"
     ]
    }
   ],
   "source": [
    "unique_x_raw, unique_y = delete_duplicate_lines(x_raw,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_positive_data_file = \"../twitter-datasets/train_pos_full.txt\"\n",
    "full_negative_data_file = \"../twitter-datasets/train_neg_full.txt\"\n",
    "x_raw_full, y_test_full = load_data_and_labels(full_positive_data_file,full_negative_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found : 9.60736% duplicates in the input\n"
     ]
    }
   ],
   "source": [
    "full_unique_x_raw, full_unique_y = delete_duplicate_lines(x_raw_full,y_test_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RT', '@marcobonzanini', ':', 'just', 'an', 'example', '!', ':D', 'http://example.com', '#NLP']\n",
      "rt marcobonzanini just an example ! d http example com nlp\n"
     ]
    }
   ],
   "source": [
    "emoticons_str = r\"\"\"(?:[:=;][oO\\-]? [D\\)\\]\\(\\]/\\\\OpP])\"\"\"\n",
    " \n",
    "regex_str = [\n",
    "    emoticons_str,\n",
    "    r'(?:@[\\w_]+)', # @-mentions\n",
    "    r\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\", # hash-tags\n",
    " \n",
    "    r'(?:(?:\\d+,?)+(?:\\.?\\d+)?)', # numbers\n",
    "    r\"(?:[a-z][a-z'\\-_]+[a-z])\", # words with - and '\n",
    "    r'(?:[\\w_]+)', # other words\n",
    "    r'(?:\\S)' # anything else\n",
    "]\n",
    "    \n",
    "tokens_re = re.compile(r'('+'|'.join(regex_str)+')', re.VERBOSE | re.IGNORECASE)\n",
    "emoticon_re = re.compile(r'^'+emoticons_str+'$', re.VERBOSE | re.IGNORECASE)\n",
    " \n",
    "def tokenize(s):\n",
    "    return tokens_re.findall(s)\n",
    " \n",
    "def preprocess(s, lowercase=False):\n",
    "    tokens = tokenize(s)\n",
    "    if lowercase:\n",
    "        tokens = [token if emoticon_re.search(token) else token.lower() for token in tokens]\n",
    "    return tokens\n",
    " \n",
    "tweet = 'RT @marcobonzanini: just an example! :D http://example.com #NLP'\n",
    "print(preprocess(tweet))\n",
    "print(clean_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
